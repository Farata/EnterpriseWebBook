:toc:
:toclevels: 4
:imagesdir: ./images

== Test-Driven Development with JavaScript

To shorten the development cycle of your Web application you need to start testing it on the early stages of the project. It seems obvious, but many enterprise IT organizations haven't adopted the agile testing methodologies, which costs them dearly. JavaScript is dynamically typed interpreted language, which means that there is no compiler to help to identifying errors as it's done in compiled languages like Java. This means that a lot more time should be allocated for testing for JavaScript Web applications. Moreover, a programmer who didn't introduce unit testing techniques into his daily routine can't be 100% sure that his code is working properly.

The static code analysis and code quality tools such as http://esprima.org/[Esprima] and http://www.jshint.com/[JSHint] will help in reducing the number of syntax errors and improve the quality of your code. Later in this chapter we will demonstrate how to setup +JSHint+ for your JavaScript project and check your code for the syntax errors automatically. 

To switch to a test-driven development mode, make testing a part of your development process in its early stages rather than scheduling testing after the development cycle is complete.

Introduction of test-driven development may substantially improve you code quality. It is very important to receive the feedback about your code on a regular basis. That's why unit tests must be automated. Ideally, the tests should run as soon as you've changed the code. In this chapter we are going to introduce Grunt - the task runner tool - that can help you with automation of repetitive operations like running unit tests when the code changes. 

There are many testing frameworks in JavaScript world, and in this chapter we'll give you a brief overview of two of them: http://qunitjs.com/[Qunit] and http://pivotal.github.com/jasmine/[Jasmine]. The main goal of each framework to is to test small pieces of code a.k.a. _units_.  We will also show how to abstract your JavaScript project lifecycle from any specific frameworks or libraries using Grunt tool.

We will go through the basic testing techniques such as "Test-driven development" and "Test First". You'll learn how to automate the testing process in multiple browsers with https://github.com/airportyh/testem[Testem Runner] or by running tests in so called _headless_ mode with http://phantomjs.org/[PhantomJS]. You'll learn how to mock and stub selected artifacts of the environment (such as `XMLHTTPRequiest` object or timer) with http://sinonjs.org/[Sinon.js] and how to unit test the DOM manipulation code.

The second part of this chapter is dedicated to setting up a new Save Sick Child project in the IDE with selected test frameworks.

=== Why Testing

Any software has bugs. But in interpreted languages like JavaScript you don't have help of compilers that could have pointed you at the potential issues on early stages of development. You need to continue testing the code over and over again to catch regression errors, to be able to add new features without breaking the existing ones. The code covered with tests is easy to refactor. Tests help to prove correctness of your code. A well tested code leads to the better overall design of your programs.

=== Testing Basics

In this chapter we are going to discuss the following types of testing (we don't cover QA and UAT in this book):

- Unit tests
- Integration tests
- Functional tests
- Load (a.k.a. stress) tests

Let's go over the strategies, approaches, and tools that will help you in automation of each of the above tests.

==== Unit Testing

The _unit test_ is a piece of code that invokes the method or class being tested. It _asserts_ some assumptions about the application logic and behavior of the  method or class. You'll be writing unit tests using a unit-testing framework. The test should run fast, be automated and readable. For example you can test that if a function is called with a particular arguments, it should return an expected result.
We will take a closer look on unit testing terminology and vocabulary in a <<TDD>> section.

==== Integration Testing

Integration testing is a phase when already tested units are combined into a module to test the interfaces between them. You may want to test the integration of your code with the code written by other developers, e.g. some framework. Integration tests ensures that any abstractions we build over the third-party code work as expected. Both unit and integration tests are written by application developers. 

==== Functional Testing

Functional testing (or acceptance testing) is aimed at finding out whether the application properly implements business logic. For example, if the user clicks on a row in the customer data grid, the program should display a form view with specific details about the selected customer. In functional testing business users should define what has to be tested, unlike unit or integration testing where tests are created by software developers. Functional tests can be performed manually by a real person clicking through each and every view of the web application, confirming that it operates properly or reporting discrepancies with the functional specifications.

But there are tools to automate the process of functional testing of Web applications. Below are brief descriptions of two of such tools - Selenium and CasperJS. 

* http://docs.seleniumhq.org/[Selenium ]
+

Selenium is an advanced browser test automation tool. Selenium tool suite has capabilities to run and record user scenarios without learning any scripting languages. Also Selenium has and API for integration with many programming languages like Java, C# and etc. Selenium uses the WebDriver API to talk to the browsers and receive running context information. WebDriver is becoming https://dvcs.w3.org/hg/webdriver/raw-file/default/webdriver-spec.html[the standard API for browser automation]. Selenium supports a wide range of http://docs.seleniumhq.org/about/platforms.jsp[browsers and platforms].

* http://casperjs.org/quickstart.html[Casper.js]
+

CasperJS is a scripting framework written in JavaScript. CasperJS allows to create the interaction scenarios like defining and ordering the navigation steps, filling and submitting forms or even scrapping the web content and making Web page screenshots. CasperJS works on top of PhantomJS browser, which limits he testing runtime environment to WebKit-based browsers only. Still it's a very useful tool when you want to run the tests in a Continuous Integration (CI)environment. You can read more about <<WHAT_IS_PHANTOMJS,PhantomJS>> and <<WHAT_IS_CI,CI>> later in the corresponding sidebars later in this chapter.

[[WHAT_IS_PHANTOMJS]]
.What is PhantomJS?
****
PhantomJS is a headless WebKit-based rendering engine with JavaScript API.  Think of PhantomJS as a browser that doesn't have any graphical user interface. PhantomJS can execute HTML, CSS, and JavaScript code. Because PhantomJS is not required to render GUI, it can be used in display-less environments (e.g. CI server) to run tests. In our case, Grunt automatically spawns PhantomJS instance, executes the code of our tests, reads the execution results using PhantomJS API, and prints them out in the console.
****


==== Load Testing

Load testing is a process that can help in answering the following questions:

* How many concurrent users can work with your application without bringing your server to its knees? 

* Even if your server is capable of serving a thousand users, is your application performance in a compliance with the Service Level Agreement (SLA), if any. 

It all comes down to two factors: availability and response time of your application. Ideally, these requirements should be well defined in the Service Level Agreement (SLA) document, which should clearly state what's acceptable from the user's perspective.For example, the SLA can include a clause stating that the initial download of your application shouldn't take longer than 10 seconds for users with a slow connections (under 1Mbps). SLA can also state that the query to display a list of customers shouldn't run for more than five seconds, and the application should be operational 99.9 percent of the time.

To avoid surprises after going live with your new mission-critical web application, don't forget to include in your project plan an item to create and run a set of heavy stress tests, and do this well in advance before your project  goes live. You don't need to hire a thousand of interns play the roles of concurrent users to find out whether your application will meet the SLA requirements.

The automated load testing software allows you to emulate required number of users, set up the throttling to emulate a slower connection, and configure the ramp-up speed. For example, you can simulate a situation where the number of users logged on to your system grows at the speed of 50 users every 10 seconds.
Stress testing software also allows you to prerecord the action of the business users, and then you can run these scripts emulating a heavy load.

Professional stress-testing software allows simulating the load close to the real-world usage patterns. You should be able to create and run mixed scripts simulating a situation in which some users are logging on to your application while others are retrieving the data and performing data modifications. Below are some tools worth considering for load testing.

* http://httpd.apache.org/docs/2.2/programs/ab.html[Apache Benchmark]
+

Apache Benchmark is a simple to use command line tool. For example, with a command `ab -n 10 -c 10 -t 60 http://savesickchild.org:8080/ssc_extjs/` Apache Benchmark will open 10 concurrent connection with the server and will send 10 requests via each connection to simulate 10 visitors working with your webapp during 60 seconds. The number of concurrent connections is the actual number of concurrent users. You can find an Apache Benchmark sample report in <<AB_REPORT,following snippet>>.

[[AB_REPORT]]
.A sample Apache Benchmark report
[source,bash]
----
This is ApacheBench, Version 2.3 <$Revision: 655654 $>
Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/
Licensed to The Apache Software Foundation, http://www.apache.org/
Server Software:    GlassFish
Server Hostname:    savesickchild.org
Server Port:    8080
Document Path:  /ssc_extjs/
Document Length:    306 bytes
Concurrency Level:  10
Time taken for tests:   60.003 seconds
Complete requests:  17526
Failed requests:    0
Total transferred:  11988468 bytes
HTML transferred:   5363262 bytes
Requests per second:    292086.73
Transfer rate:  199798.72 kb/s received
Connnection Times (ms)
             min avg max
Connect:     10  13  1305
Processing:  11  14  12
Total:       21  27  1317
----

* http://jmeter.apache.org/[jMeter]
+

Apache JMeter is a tool with a graphic user interface. It can be used to simulate heavy load on a server, network or an object to test its strength or to analyze overall performance under different load types. You can find more about testing web applications using JMeter in http://jmeter.apache.org/usermanual/build-web-test-plan.html[official documentation].

.JMeter test results output example
image::fig_08_17.png[]

* http://phantomjs.org/[PhantomJS]
+

Please, refer the sidebar called <<WHAT_IS_PHANTOMJS,What is PhantomJS>> to make yourself familiar with this tool. You can read more how you can use PhantomJS for performance testing of your application in presentation called http://wesleyhales.com/slides/html5devconf2013/["Browser Performance metering with PhantomJS"].

[[TDD]]
=== Test Driven Development

The methodology known as Test-Driven Development (TDD) substantially changes the way a "classic" software development is done. This methodology wants you to write tests _even before_ writing the application code. Instead of just using testing to verify our work _after it's done_, TDD moves the testing into the earlier application design phase. You should use the tests to clarify your ideas about what you are about to program. Here is fundamental mantra of TDD:

- Write a test and make it fail.
- Make the test pass.
- Refactor.
- Repeat.

This technique also referred as "Red-Green-Refactoring" because IDE's and test runners use red color to indicate failed test and green color to indicate passed tests.

When you are about to start programming a class with some business logic, ask yourself, "How can I ensure that this function works fine?" After you know the answer, write a test JavaScript class that calls this function _to assert_ that the business logic gives the expected result. 

An assertion is a true-false statement that represents what a programmer assumes about program state, e.g.  *customerID >0* is an assertion. 

According to <<fowler, 'Martin Fowler'>>, an assertion is a sections of code work only if certain conditions are true. An assertion is a conditional statement that is assumed to be always true. Failure of an assertion results in test failure. 

Run your test, and it  will immediately fail because no application code is written yet! Only after the test is written, start programming the business logic of your application 

You should write a simplest possible piece of code to make the test pass. Don't try to find a generic solution at this step. For example, if you want to test calculator that needs to return `4` as result of `2+2` write the code what simply returns `4`. Don't worry about performance or optimization on this step. Just make the test pass. Once you made it, you can refactor your application code. Now you might want to introduce a real algorithm for implementing the application logic without worrying about breaking the  contract with other components of your application. 

A failed unit test indicates that your code change introduced regression, which is a new bug in a previously worked software. Automated testing and well-written test cases can reduce the likelihood of a regression in your code.

TDD allows to receive feedback from your code almost immediately. It's better to find that something is broken during development rather than in the application deployed in production.

[NOTE]
===============================
And learn by heart The Golden Rule Of TDD:
____
Never write new functionality without a failing test
____
===============================

In addition to business logic, web applications should be tested for proper rendering of UI components, changing view states, dispatching, and handling events.

With any testing framework, your tests will follow same basic pattern. First, you need to setup up the test environment. Second, you run the  production code and check that it works as it supposed to. 

Finally, you need to clean up after the test will run - remove everything that your program has created during setup of the environment.

[[AAAR]]This pattern for authoring unit tests is called _Arrange-Act-Assert_ (AAA footnote:[ http://integralpath.blogs.com/thinkingoutloud/2005/09/principles_of_t.html[Principles for Test-Driven Development] ]).

In the _Arrange_ phase you set up the unit of work to test. For example, create a DOM element.

In the _Act_ phase you exercise the unit under test and capture the  resulting state. You execute your production code in unit test context.

In the _Assert_ phase you verify the behavior through assertions.

There is one more phase: _Reset_. In this phase, if needed, you reset the environment to the initial state. For example, erase the DOM elements created in the _Arrange_ phase.

Later in this chapter, you'll see how different frameworks implements _AAAR_ pattern.

==== Automate Everything

You should automate testing as much as you can to reduce the costs of building, deploying, and maintaining your application. 

Now lets start building the foundation for our refactored application. We are going to use the tasks running framework for the JavaScript project called http://gruntjs.com/[Grunt]. With Grunt's help we'll automate process of running tests once the code changes. The tests should help in assessing the quality of our code. You'll learn how to setup Grunt to watch your code changes and run tests right after you modified the code and saved the changes. 

With the Grunt tool you can have a script to run all your tests. In you came from the Java world, you know about Apache Ant, a general-purpose command-line tool for drive processes described in build files as targets. Grunt also running the tasks described in. There is a wide range of tasks available today - starting with running automated unit tests and ending with JavaScript code minification. Grunt provides a separate layer of abstraction where you can define tasks in special DSL (domain-specific language) in Gruntfile and Grunt will execute it.

===== The Simplest Grunt File

.Node.js, V8, and NPM
****
Node.js (or simply Node) is a server-side event-driven framework. Node uses V8, the JavaScript engine by Google used in Chrome/Chromium. The V8 engine provides JavaScript API for accessing the file system, sockets and  running processes. The Grunt tool is built on top of Node JavaScript APIs. You can find more information about Node.js at  http://nodejs.org/about/[their website].

Node Package Manager (NPM) is a utility as well as https://npmjs.org/[community repository] for open source JavaScript projects. NPM provides unified API and metadata model for managing dependencies in JavaScript projects. A `package.json` file is the project's dependencies descriptor. NPM installs project dependencies using information from `package.json`.

Node and NPM are cross-platform software and binaries available for Windows, Linux and Mac OS X operating systems. 

To use examples in you need to download and install Node from http://nodejs.org/download/[official web site]. Then follow http://gruntjs.com/getting-started[ the instructions from Grunt's  website] to install it on your machine.
****

Let's start with the simplest Grunt project setup. The following two files must be present in the project directory:

* `package.json`: This file is used by NPM to store metadata and a project dependencies. 
+
List Grunt and its plugins that your project needs as _devDependencies_ in this file.

* `Gruntfile`: This file is named `Gruntfile.js` or `Gruntfile.coffee` and is used to configure or define the tasks and load Grunt plugins.

.The simplest possible Gruntfile
[source,javascript]
----------------------------------------------------------------------
module.exports = function (grunt) {
    'use strict';

    grunt.registerTask('hello', 'say hello', function(){    // <1>
        grunt.log.writeln("Hello from grunt");              // <2>
    });

    grunt.registerTask('default', 'hello');                 // <3>              
};
----------------------------------------------------------------------

<1> Register a new task named `hello`.

<2> Print the greeting text using http://gruntjs.com/api/grunt.log[grunt's log API].

<3> With `grunt.registerTask` we define a default task to run when Grunt is called without any parameters. 

Each task can be called separately from the command line by passing the task's name as a command line parameter: For example `grunt hello` would only execute the task named hello from the above script.

Let's run this `hello` task with the following command 
`grunt --gruntfile Grunt_simple.js hello`.

[source,bash]
----------------------------------------------------------------------
Running "hello" task
Hello from grunt

Done, without errors.
----------------------------------------------------------------------

Now after you have learned of basics of Grunt tool we can use it for something more interesting than just printing "_hello world_" string on the screen. Since JavaScript is a interpreted language there is no compiler to help catch syntax errors. But you can use http://www.jshint.com/[JSHint], an open source tool, which helps with identifying errors in JavaScript code in lieu of compiler. Consider the following JavaScript <<LISTING_WITH_ERRORS,code>>.

.A JavaScript array with a couple typos
[[LISTING_WITH_ERRORS]]
[source,javascript]
----
include::include/jshint_example.js[]
----
<1> We want to define array that contains names of actors who played James Bond in a canonical series.

<2> Here is example of typical typo. Developer commented line contains array element but left coma in previous line.

<3> A missing semicolon is a typical typo. It is not actual error, but omitting semicolon is not a good habit. An automatic semicolon insertion (ASI) will get you covered in this case.

.What is a Automatic Semicolon Insertion?
****
In JavaScript, you can omit a semicolon between two statements written in separate lines. Automatic semicolon insertion is a source code parsing procedure that infers omitted semicolons in certain contexts into your program. You can read more about optional semicolons in JavaScript in the chapter "Optional Semicolons" in  <<flanagan, 'JavaScript. Definitive Guide. 6th Edition'>> book.
****

The above code snippet is a fairly simple example that can cause trouble and frustration if you don't have proper tools to check the code semantics and syntax. 
Let's see how JSHint can help with it. JSHint as well as many other JavaScript open source projects can be installed via NPM with command `npm install jshint -g`. Now you can run JSHint against our code snippet:

[source,bash]
----
> jshint jshint_example.js
jshint_example.js: line 7, col 27, Extra comma. (it breaks older versions of IE)
jshint_example.js: line 9, col 10, Missing semicolon. # <1>

2 errors            # <2>
----
<1> JSHint reports the location of error and a short description of the problem.
<2> The total count of errors 

TIP: WebStorm IDE has http://blogs.jetbrains.com/idea/2012/05/lint-your-javascript-with-jslintjshint-in-real-time/[built-in support] for JSHint tool. There is 3rd party plugin for Eclipse - http://github.eclipsesource.com/jshint-eclipse/[jshint-eclipse].

Grunt also has a task to run JSHint against your JavaScript code base. Here is how JSHint configuration in Grunt looks like.

.A grunt file with JSHint support
[source,javascript]
----
module.exports = function(grunt) {
  grunt.initConfig({
    jshint: {
      gruntfile: {          // <1>
        src: ['Gruntfile_jshint.js']
      },
      app: {
        src: ['app/js/app.js']
      }
    }
  });
  grunt.loadNpmTasks('grunt-contrib-jshint');       
  grunt.registerTask('default', ['jshint']);        // <2>
};
----
<1> Because Gruntfile is JavaScript file, JSHint can check it as well and identify the errors.

<2> When grunt will be run without any parameters, default task +jshint+ will be triggered.

[source,bash]
----
> grunt 

Running "jshint:gruntfile" (jshint) task
>> 1 file lint free.

Running "jshint:app" (jshint) task
>> 1 file lint free.

Done, without errors.
----

Another handy task that to use in developer's environment is the `watch` task. A purpose of this task is to monitor files in pre-configured locations. When the watcher detects any changes in those files it will run the configured task. Here is how a <<LIST_WATCH_TASK,watch task config>> looks like:

.A `watch` task config 
[source,javascript]
----
module.exports = function(grunt) {
    grunt.initConfig({
        jshint: {
            // ... configuration code is omitted 
        },
        watch: {        // <1>
            reload: {
                files: ['app/*.html', 'app/data/**/*.json', 'app/assets/css/*.css', 'app/js/**/*.js', 'test/test/tests.js', 'test/spec/*.js'],  // <2>
                tasks: ['jshint']           // <3>
            }
        }
    });
    grunt.loadNpmTasks('grunt-contrib-jshint');
    grunt.loadNpmTasks('grunt-contrib-watch');
    grunt.registerTask('default', ['jshint']);
};
----

<1> Watch task configuration starts here

<2> The list of the files that need to be monitored for changes

<3> A array of tasks to be triggered after file change event occurs

[source,bash]
----
> grunt watch

Running "watch" task
Waiting...OK
>> File "app/js/Player.js" changed.
Running "jshint:gruntfile" (jshint) task
>> 1 file lint free.

Running "jshint:app" (jshint) task
>> 1 file lint free.

Done, without errors.

Completed in 0.50s at Tue May 07 2013 00:41:42 GMT-0400 (EDT) - Waiting...
----

Later in this chapter we will use the `watch` task to automatically run tests after the production code or the code of the tests is changed.

In this section we've introduced a convenient tool - the task runner Grunt - that can be used to automate different aspects of the JavaScript development workflow. We will use Grunt to perform syntax and semantic checks of your code with JSHint. Also, to minimize repetitive tasks we showed hot to setup `watch` task to monitor changes in our code base.

In next sections we will dive into the testing frameworks for JavaScript. Our fist stop is QUnit.

==== Test-Driven Development With QUnit

We'll start our journey to JavaScript testing frameworks with http://qunitjs.com/[QUnit], which was originally developed by http://ejohn.org/about/[John Resig] as part of jQuery. QUnit now runs completely standalone and doesn't have any jQuery dependency. While it's still being used by the jQuery Project itself for testing jQuery, jQuery UI and jQuery Mobile code, QUnit can be used to test any generic JavaScript code.

===== Setup Grunt With Qunit

WARNING: Section is in active development

In this section you're going learn how to automatically run the Qunit tests using Grunt. Let's setup our project by adding the Qunit framework and tests file. We'll start with downloading the latest version from http://qunitjs.com/[QUint Web site]. We need to get only two files - `qunit-*.js` and `qunit-*.css`.

.A download section on QUnit website
image::fig_08_04.png[]

.QUnit framework in our project 
image::fig_08_05.png[]

.Our first QUnit test
[source,javascript]
----
'use strict';
test("my first qunit test", function () {
    ok(2 + 2 === 4, "Passed!");
});
----

We'll also need a test runner for the test setup. 

.A test runner
[source,html]
----
<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>QUnit Example</title>
    <link rel="stylesheet" href="lib/qunit-1.11/qunit.css"> 
    <script src="lib/qunit-1.11/qunit.js"></script>     <!-- <1> -->
    <script type="text/javascript" src="../app/js/libs/jquery-1.9.0.min.js"></script> <!-- <2> -->
    <script src="test/tests.js"></script>               <!-- <3> -->
</head>
<body>
<div id="qunit"></div> <!-- <4> -->
<div id='qunit-fixture'>
    <!-- <5> -->
</div>
</body>
</html>
----

<1> A test runner is an html file contains links to QUnit framework JavaScript file.

<2> In this chapter we continue working on the jQuery-based version of the Save Sick Child application. Hence our "production environment" depends on availability of jQuery, so we need to include jQuery in the test runner.

<3> Test files are included too.

<4> QUnit fills this block with results.

<5> Any HTML you want to be present in each test. It will be reset for each test.

To run all our tests we need to open the `qunit-runner.html` in browser.

.A test run results in browser
image::fig_08_06.png[]

.Gruntfile with qunit runner
[source,javascript]
----
module.exports = function (grunt) {
    "use strict";
    grunt.initConfig({
        qunit: {
            all: ["test/qunit-runner.html"]
        }
    });
    grunt.registerTask("test", "qunit");
    grunt.loadNpmTasks("grunt-contrib-qunit");
};
----

Now let's briefly review QUnit API components. You can find a typical QUnit script in <<QUNIT_TEST,the following listing>>.

[[QUNIT_TEST]]
.A sample QUnint test
[source,javascript]
----
(function($) {  
    module('SaveSickChild: login component test', { // <1>
        setup: function() { // <2>
            // test setup code goes here
        },
        teardown: function() {  // <3>
            // test cleanup code goes here
        }
    });
    test('jquery is here', function() {     // <4>
        ok($, "yes, it's here");
    });
    test("2 add 2 equals 4", function() {
        ok(2 + 2 === 4, "Passed!");     // <5>
    });
    test('2 add 2 not equals 5', function() {
        notEqual(2 + 2, 5, "failed");       // <6>
    });
}(jQuery));     // <6>
----
<1> A `module` function allows to combine related tests as group.

<2> Here we can run _Arrange_ phase. A `setup` function will be called before each test.

<3> A `teardown` function will be call after each test respectively. This is our _Reset_ phase.

<4> You need to place code of your test in corresponding `test` function.

<5> Typically, you need to use assertions to make sure the code being tested  gives expected results. The function http://api.qunitjs.com/ok/[`ok`] will examine the first argument to be `true`. 

<6> A pair of functions `equal` and `notEqual` will check for the equivalence of the first and second arguments. Arguments could be expressions as well.

<7> A code of the test is wrapped in immediate-invoked function expression (IIFE) and passes `jQuery` object as `$` variable.

You can find more details about QUnit in http://api.qunitjs.com/[product  documentation] and http://qunitjs.com/cookbook/[QUnit Cookbook].         


==== Behavior-Driven Development With Jasmine

The idea behind _behavior-driven development_ (BDD) is to use the "natural language" constructs to describe what you think your code should be doing or more specifically, what your functions should be returning.

Similarly to unit tests, with BDD you write short specifications that test one feature at a time. Specifications should be sentences. For example, "Calculator adds two positive numbers". Such sentences will help you to easy identify the failed test by simply reading this sentence in test results report. Now we'll demonstrate this concept using Jasmine - the BDD frameworks for JavaScript. Jasmine provides a very nice way to group, execute, and report JavaScript unit tests. 

// TBD

===== Setup Grunt with Jasmine

You've learned already how to use Grunt tool to automate boilerplate tasks. In this section we're going to show how you can execute a Jasmine specification with Grunt. We'll cover the Jasmine basics in the next section, but for now think of Jasmine as a piece of code that should be executed by Grunt.

Let's start with downloading the latest version of Jasmine from https://github.com/pivotal/jasmine/downloads[its github repository]. Unzip the archive. The content of unzipped folder will look similar to the screenshot <<FIG-1>>.

.Jasmine Distribution
[[FIG-1]]
image::fig_08_01.png["Jasmine distribution"]

Jasmine comes with an example spec (_spec_ folder) and an html test runner - SpecRunner.html. Let's open the file SpecRunner.html in browser <<FIG-2>>. 

.Running Jasmine Specs in a Browser
[[FIG-2]]
image::fig_08_02.png["SpectRunner.html"]

The SpecRunner.html is structured similarly to qunit html runner. You can run specifications by opening the runner file in browser.  

[source, html]
----------------------------------------------------------------------
include::include/SpecRunner.html[]
----------------------------------------------------------------------

<1> Required Jasmine framework library
<2> Include source files
<3> Include specs code
<4> Initialize Jasmine and run all specifications when the page is loaded

Now let's update our Grunfile to run the same sample specifications with the headless browser. Copy the content of +src+ folder of your Jasmine distribution into the `app/js` folder of our project, and then copy the content of the `spec` folder into the `test/spec` folder of your project. Also create a folder `test/lib/jasmine` and copy the content of Jasmine distribution `lib` folder there. <<FIG-3>>

.Jasmine Specifications in Our Project
[[FIG-3]]
image::fig_08_03.png[]

Now you need to edit Gruntfile.js to activate Jasmine support.

.Gruntfile_jasmine.js with Jasmine running support 
[source,javascript]
----------------------------------------------------------------------
module.exports = function (grunt) {
    'use strict';

    grunt.initConfig({
        jasmine: {  // <1>
            src: ['app/js/Player.js', 'app/js/Song.js'], // <2> 
            options: {
                specs: 'test/spec/PlayerSpec.js',   // <3>
                helpers: 'test/spec/SpecHelper.js'  // <4>
            }
        }
    });

    // Alias the `test` task
    grunt.registerTask('test', 'jasmine');
    // loading jasmine grunt module
    grunt.loadNpmTasks('grunt-contrib-jasmine');
};
----------------------------------------------------------------------

<1> Configuring Jasmine task
<2> Specifying the location of the source files
<3> Specifying the location of Jasmine specs
<4> Specifying the location of Jasmine helpers (will be covered later in this chapter)

To execute tests, run the command `grunt --gruntfile Gruntfile_jasmine.js jasmine`, and you should see something like this:

[source,bash]
----
Running "jasmine:src" (jasmine) task
Testing jasmine specs via phantom
.....
5 specs in 0.003s.
>> 0 failures

Done, without errors.
----

In this example, Grunt successfully executed the tests with <<WHAT_IS_PHANTOMJS,PhantomJS>> of all five specifications defined in PlayerSpec.js. 

[[WHAT_IS_CI]]
.What is Continuous Integration?
****
Continuous Integration (CI) is a software development practice where members of a team integrate their work frequently, which results in multiple integrations per day.
Introduced by Martin Fowler and Matthew Foemmel, the theory of continuous integration footnote:[http://martinfowler.com/articles/continuousIntegration.html[Continuous Integration by Martin Fowler]] recommends creating scripts and running automated builds (including tests) of your application at least once a day.
This allows you to identify issues in the code early.

The authors of this book successfully use an open source framework called http://jenkins-ci.org/[Jenkins] (there are other similar CI servers) for establishing continuous build process.

With Jenkins, you can have scripts that run either at a specified time interval or on each source code repository check-in of the new code. You may also force an additional build process whenever you like. The Grunt command line tool should be installed and be available on CI machine to allow the Jenkins server invoke Grunt scrips and publish test results.

// TODO: Add screenshot with grunt-based job for savesickchild.org website + test results 

We use it to ensure continuous builds of the internal and open source projects.

.Jenkins CI server running at savesichild.org website and used to build the sample applications for this book.
image::fig_08_07.png[Jenkins]
****

In the next section you will learn how write your own specifications.

===== Jasmine Basics

After we've set up the tools for running tests, let's start developing tests and learn the Jasmine framework constructs. Every specification file has a set of _suites_ defined in the `describe` function. Suites help logically organize code of test specifications. 

.ExampleSpec.js
[source,javascript]
----
describe("My function under test should", function () {     // <1>
    it("return on", function () {                           // <2>
        // place specification code here
        //
    });
    describe("another suite", function () {                   // <3>
        it("spec1", function () {

        });
    });
    it("my another spec", function () {                    // <4>
        var truth = true;
        expect(truth).toBeTruthy();
    });
    it("2+2 = 4", function () {
        expect(2 + 2).toEqual(4);                       // <5>
    });
});
----

<1> The function `describe` accepts two parameters - the name of the test suite, and the callback function. The function is a block of code that implements the suite. If for some reasons you would like to skip the suite from execution you can just use method `xdescribe` and a whole suite will be excluded until you rename it back to `describe`.

<2> The function `it` also accepts similar parameters - the name of the test specification, and the function that implements this specification. Like in case with suites, Jasmine has a corresponding `xit` method to exclude specification from execution.

<3> Each suite can have any number of nested suites.

<4> Each suite can have any number of specifications.

<5> The code checks to see if `2+2` equals `4`. We used the function `toEqual()`, which is a _matcher_. Define expectations with the function `expect`, which takes a value, called the actual. It's chained with a Matcher function, which takes the expected value (in our case it's 4) and checks if it satisfies the criterion defined in the matcher. Various flavors of matchers are shipped with Jasmine framework, and we're going to review a couple the frequently used matchers functions.

* Equality
+

Function `toEqual()` checks if two things are equal.

* True or False?
+

Functions `toBeTruthy()` and `toBeFalsy()` checks if something is true or false respectively.

* Identity
+

Function `toBe()` checks if two things are _the same object_.

* Nullness
+

Function `toBeNull()` checks if something is +null+.

* Is Element Present
+

Function `toContain()` check if an actual value is an element of array.
+

[source, javascript]
----
expect(["James Bond", "Austin Powers", "Jack Reacher", "Duck"]).toContain("Duck");
----

* Negate Other Matchers
+

This function is used to reverse matchers to ensure that they aren't +true+. To do that, simply prefix things with `.not`:
+

[source, javascript]
----
expect(["James Bond", "Austin Powers", "Jack Reacher"]).not.toContain("Duck");
----

Above we've listed only some of existing matchers. You can find the complete documentation with code examples at http://pivotal.github.io/jasmine/#section-Matchers[official Jasmine website] and at https://github.com/pivotal/jasmine/wiki/Matchers[wiki].

===== Specification Setup

Jasmine framework has an API to arrange your specification (see <<AAAR>>). It includes two methods - `beforeEach()` and `afterEach()`, which allow you to execute some code before and after each spec respectively. It's very useful for instantiation of the shared objects or cleaning up after the tests complete.
If you need to fulfill your test with some common dependencies or setup the environment, just place code inside `beforeEach()` method. Such dependencies and environment are known as _fixture_.

****
*What is Fixture?*
Test fixture refers to the fixed state used as a baseline for running tests. The main purpose of a test fixture is to ensure that there is a well known and fixed environment in which tests are run so that results are repeatable. Sometimes a fixture also referred as _test context_.
****

.Specification setup with beforeEach
[source,javascript]
----
(function($) {
    describe("DOM manipulation spec", function() {
        var usernameInput;
        var passwordInput;
        beforeEach(function() {         // <1>
            usernameInput = document.createElement("input");       // <2>
            usernameInput.setAttribute("type", "text");
            usernameInput.setAttribute("id", "username");
            usernameInput.setAttribute("name", "username");
            usernameInput.setAttribute("placeholder", "username");
            usernameInput.setAttribute("autocomplete", "off");

            passwordInput = document.createElement("input");
            passwordInput.setAttribute("type", "text");
            passwordInput.setAttribute("id", "password");
            passwordInput.setAttribute("name", "password");
            passwordInput.setAttribute("placeholder", "password");
            passwordInput.setAttribute("autocomplete", "off");
        });

        afterEach(function () { // <3>

        });

        it("jquey should be present", function() {
            expect($).not.toBeNull();
        });
        it("inputs should exist", function() {
            expect(usernameInput.id).toBe("username");
            expect(passwordInput.id).toBe("password");
        });
        it("should not allow login with empty username and password and return code equals 0", function() {
            var result = ssc.login(usernameInput, passwordInput);   // <4>
            expect(result).toBe(0);
        });
        it("should allow login with user admin and password 1234 and return code equals 1", function() {
            usernameInput.value = "admin";      // <5>
            passwordInput.value = "1234";
            var result = ssc.login(usernameInput, passwordInput);  
            expect(result).toBe(1);
        });
    });
})(jQuery);
----

<1> This method will be called before each specification.

<2> In the `beforeEach()` method we create two input fields. These two inputs will be available in all specifications of this suite.

<3> You can place additional cleanup code inside `afterEach()` function.

<4> A `beforeEach()` function helps to implement _Don't Repeat Yourself_ principle in our tests. You don't need to create the dependency elements inside each specification manually.

<5> You can change defaults inside each specification without worrying about  affecting other specifications. Your test environment will be reset for each specification.


===== Custom Matchers

Jasmine framework is easily extendable, and it allows you to define your own matchers if for some reasons you're unable to find the appropriate matchers in the Jasmine distribution. In such cases you'd need to write a custom matcher. Let's write a matcher that check if a string contains name of the "secret agent" from the defined list of agents. 

.Custom `toBeSecretAgent` matcher
[source,javascript]
----
beforeEach(function () {
    this.addMatchers({
        toBeSecretAgent: function () {
            var agentList = [
                "James Bond",
                "Ethan Hunt",
                "Jason Bourne",
                "Aaron Cross",
                "Jack Reacher"
            ];

            var actual = this.actual;               // <1>
            this.message = function () {            // <2>
                return actual + " is not a secret agent";
            };
            return agentList.indexOf(actual) !== -1;    // <3> 
        }
    });
});
----

<1> `this.actual` contains the value used as arguments in the `expect` function.

<2> We can customize error message if the test fails.

<3> This function checks if `agentsList` contains the actual value.

The invocations of this helper can look like this:

[source,javascript]
----
it("part of super agents", function () {
    expect("James Bond").toBeSecretAgent();         // <1>
    expect("Jason Bourne").toBeSecretAgent();
    expect("Austin Powers").not.toBeSecretAgent();  // <2>
    expect("Austin Powers").toBeSecretAgent();     // <3>
});
----

<1> Calling the custom matcher.

<2> Custom matchers could be used together with the `.not` modifier.

<3> This expectation will fail because 'Austin Powers' is not in the list of secret agents.

The following custom failure message will be displayed on the console.
    
[source,bash]
----
/usr/local/share/npm/bin/grunt --gruntfile Gruntfile_jasmine.js jasmine
Running "jasmine:src" (jasmine) task
Testing jasmine specs via phantom
...........x
My function under test should:: part of super agents: failed
  "Austin Powers is not a secret agent (4)"               # <1>
1 specs in 0.115s.
>> 1 failures
Warning: Task "jasmine:src" failed. Use --force to continue.

Aborted due to warnings.
----

<1> A custom failure message. Also, the failed `expect` was the fourth one (4) according to the order mentioned in spec.

===== Spies

Test spies are objects and functions that record information about their usage through the systems under test. They are useful when determining a function's success is not easily accomplished by inspecting its return value or changes to the state of objects with witch it interacts. 

Consider the following example of login functionality. A `showAuthorizedSection()` function will be invoked within `login` function after the user entered the correct username and password. We need to test that the invocation of the `showAuthorizedSection()` is happening in this sequence.

[[LOGIN_SNIP]]
.Production code of `login` function.
[source,javascript]
----
var ssc = {};
(function() {
    'use strict';
    ssc.showAuthorizedSection = function() {
        console.log("showAuthorizedSection");
    };
    ssc.login = function(usernameInput, passwordInput) {
        // username and password check logic is omitted
        this.showAuthorizedSection();
    };
})();
----

And here is how we can test it using Jasmine's spies.

[source,javascript]
----
describe("login module", function() {
    it("showAuthorizedSection has been called", function() {
        spyOn(ssc, "showAuthorizedSection"); // <1>
        ssc.login("admin", "1234"); // <2>
        expect(ssc.showAuthorizedSection).toHaveBeenCalled(); // <3>
    });
});
----
<1> A `spyOn` function will replace `showAuthorizedSection` function with corresponded spy.
<2> `showAuthorizedSection` function will be invoked within `login` function in case of successful login.
<3> Assertion `toHaveBeenCalled()` would be not possible without spy.


// ===== BDD Best Practices
// TBD
// Organize Tests As If Reading a Story
// Test method names should be sentences
// Developers discovered it could do at least some of their documentation for them, so they started to write test methods that were real sentences. What's more, they found that when they wrote the method name in the language of the business domain, the generated documents made sense to business users, analysts, and testers.
// A simple sentence template keeps test methods focused 
// An expressive test name is helpful when a test fails 

==== Multi-Browser Testing

The previous section was about executing your test and specification in a headless mode using PhantomJS, which is very useful for running tests in the Continuous Integration environments. While PhantomJS uses WebKit rendering engine, there are browsers that don't use WebKit. It's obvious that running tests manually in each browser is tedious and not productive.
To automate testing in all Web browsers, you can use Testem Runner. In this section you'll learn how to install and configure `Testem` to run Jasmine tests.

===== Installation

Testem uses Node.js APIs and can be installed with NPM:

[source,bash]
----
npm install testem -g
----

===== Testem Configuration file

Testem runner will just pick any of JavaScript in your project directory. If testem can identify any tests among that +.js+ files it will run it.
But Testem tasks can be customize using a configuration file. 
You can configure Testem to specify which files should be included in testing. Testem starts with trying to find the configuration file _testem.json_ in the project directory. A sample `testem.json` is shown in <<TESTEM_JSON,following listing>>. 

[[TESTEM_JSON]]
.A Testem Configuration File
[source,javascript]
----
{
    "framework": "jasmine",         // <1>
    "src_files": [                 // <2> 
        "ext/ext-all.js",
        "test.js"
    ]
}
----
<1> The `framework` directive is used to specify the test framework. Testem supports Qunit, Jasmine and many more frameworks. You can find full list of supported frameworks on testem https://github.com/airportyh/testem#features[github page].

<2>  The list of test and production code source files. 

===== Running Tests 

Testem supports two running modes: test-driven-development mode (_tdd-mode_)  and continuous integration (_ci-mode_). In tdd-mode, testem starta the  development server.

.Testem tdd-mode.
image::fig_08_13.png[]

In tdd-mode, Testem doesn't spawn any browser automatically. On the contrary, you'd need to open this url in the browser you want run test against to connect it to testem server. From this point on, testem will execute tests in all connected browsers.  On the next <<TESTEM_MULTI,screeshot>> you can see we added different browsers including mobile version of Safari (running on iOS simulator).

[[TESTEM_MULTI]]
.Testem is running the tests on the multiple browsers.
image::fig_08_14.png[]

Because testem server itself is an HTTP server, you can connect remote browsers to it as well. For example, the <<TESTEM_IE, following screenshot>> shows Internet Explorer 10 running under Windows 7 virtual machine connected to the testem server.

[[TESTEM_IE]]
.Using testem to test code on remote IE 10
image::fig_08_16.png[]

Running the tests with testem runner can be combined with previously introduced tool. The <<TESTEM_AND_GRUNT,next screenshot>> shows that testem runs tests on the real browsers and and grunt runs tests on the headless PhantomJS.

[[TESTEM_AND_GRUNT]]
.Using testem and `grunt watch` side-by-side 
image::fig_08_15.png[]

As you seen in <<TESTEM_IE, previous screenshot>>, we can use 
But Testem itself supports live reloading mode. This means that testem will watch file system for changes and will execute tests in all connected browsers automatically. You can force to test run by switching to console and hitting the _Enter_ key.

In the continuous integration mode testem will examine system for all of the available browsers in your system and will execute tests on it. You can get list of the browsers that testem can use to run tests with the `testem launchers` command. <<TESTEM_L,Here is sample output>> after runnin this command. 

[[TESTEM_L]]
----
# testem launchers
Have 5 launchers available; auto-launch info displayed on the right.

Launcher      Type          CI  Dev
------------  ------------  --  ---
Chrome        browser       ✔
Firefox       browser       ✔
Safari        browser       ✔
Opera         browser       ✔
PhantomJS     browser       ✔
----

Now you can run our test simultaneously in all browsers installed on  your computer - Google Chrome, Safari, Firefox, Opera and PhantomJS - with one command:

`testem ci`

.An output of `testem ci` command
[source,bash]
----
# Launching Chrome      # <1>
# 

# Launching Firefox     # <2>
# ....
TAP version 13
ok 1 - Firefox Basic Assumptions:  Ext namespace should be available loaded.
ok 2 - Firefox Basic Assumptions:  ExtJS 4.2 should be loaded.
ok 3 - Firefox Basic Assumptions:  SSC code should be loaded.
ok 4 - Firefox Basic Assumptions:  something truthy.

# Launching Safari      # <3>
# 

# Launching Opera       # <4>
# ....
ok 5 - Opera Basic Assumptions:  Ext namespace should be available loaded.
ok 6 - Opera Basic Assumptions:  ExtJS 4.2 should be loaded.
ok 7 - Opera Basic Assumptions:  SSC code should be loaded.
ok 8 - Opera Basic Assumptions:  something truthy.

# Launching PhantomJS       # <5>
# 

1..8
# tests 8
# pass  8

# ok
....
----
<1> The tests are run on Chrome...
<2> ... Firefox
<3> ... Safari 
<4> ... Opera
<5> ... and on headless WebKit - PhantomJS

Testem uses http://en.wikipedia.org/wiki/Test_Anything_Protocol[TAP] format to report test results. 

==== Testing DOM

Document Object Model is a standard browser API that allows a developer to access and manipulate page elements. As you have seen in previous chapters, pretty often your JavaScript code needs to access and manipulate the HTML page elements in some way. Testing the DOM is the crucial part of testing your client side JavaScript. 
By design, DOM is a browser-agnostic API. But in the real world, if you want to make sure that your code works in the particular browser you need to run the test inside this browser.

Earlier in this chapter we've introduced the Jasmine method `beforeEach()`, which is the right place for setting all required DOM elements and making them available in the specifications.

.Using jQuery APIs to create the required DOM elements before run the spec
[[FIX-1]]
[source,javascript]
----
describe("spec", function() {
    var usernameInput;
    beforeEach(function() { // <1>
        usernameInput = $(document.createElement("input")).attr({ // <2>
            type: 'text',
            id: 'username',
            name: 'username'
        })[0];
    });
});
----
<1> Inside the `beforeEach()` method we're using the API to manipulate the DOM programatically. Also, if you're using an HTML test runner you can add the fixture using HTML tags. But we don't recommend this approach. Very soon you will find your HTML test runner will become unmaintainable because it's going to get clogged with tons of fixture HTML code.

<2> Create an `<input>` element using jQuery APIs, which will turn into the following HTML:   

[source,html]
----
<input type=​"text" id=​"password" name=​"password" placeholder=​"password" autocomplete=​"off">​
----

The jQuery API is more convenient than a plain DOM API. But in the future examples we will use the https://github.com/searls/jasmine-fixture[jasmine-fixture] library for easier setup of the DOM fixture. Jasmine-fixture uses similar to jQuery selectors syntax for injecting HTML fixtures. With this library you will significantly decrease the amount of repetitive code while creating the fixtures.

// TODO: add jasmine-fixture setup, how to download and add to jasmine Grunts's task

Let's see how the example from <<FIX-1,previous code snippet>> looks like with the jasmine-fixture library.

.Using jasmine-fixture to setup the DOM before spec run
[source,javascript]
----
describe("spec", function() {
    var usernameInput;
    beforeEach(function() {
        usernameInput = affix('input[id="username"][type="text"][name="username]')[0]; // <1>
    });

    it("should not allow login with empty username and password and return code equals 0", function() {
        var result = ssc.login(usernameInput, passwordInput); // <2>
        expect(result).toBe(0);
    });
});
----
<1> Using the `affix()` function provided by the jasmine-fixture library and expressiveness of CSS selectors we can easily setup required DOM elements. More examples of possible selectors could be found at the https://github.com/searls/jasmine-fixture#more-examples[documentation page] of jasmine-fixture.

<2> Now when all requirements for our production code (`login()` function) are satisfied we can run it in the context of a test and assert the results.

As you can see, testing of the DOM manipulation code is much like any other type of unit testing. You need to prepare a fixture (a.k.a. the testing context), run the production code and assert the results.

// TBD Ext JS create fixture div tag, render extjs component on it

// TBD faking events and user interaction
// TBD using spies to mock code related to interaction with server

=== Save Sick Child With TDD

==== The Test-Driven ExtJS version of _SaveSickChild.org_

WARNING: This section is under active development

In this section we will use your newly acquired Ext JS skills - we assume that you've read the materials from Chapter 6. As a reminder, Ext JS framework encourages using MVC architecture. The separation of responsibilities between Views, Models and Controllers makes an ExtJS application a perfect candidate for unit testing.  In this section we'll show how to test the Ext JS version of the Save Sick Child application from Chapter 6.

//TBD
===== Harnessing ExtJS application

Let's create a skeleton application that can provide for our classes under the test familiar environment. 

.A HTML-runner for Jasmine and ExtJS application
[source,html]
----
<!doctype html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title id="page-title">ExtJS Jasmine Tester</title>
    <link rel="stylesheet" type="text/css" href="test/lib/jasmine-1.3.1/jasmine.css"/>
    <script type="text/javascript" src=ext/ext-all.js></script> // <1>

    <script type="text/javascript" src="test/lib/jasmine-1.3.1/jasmine.js"></script> //<2>
    <script type="text/javascript" src="test/lib/jasmine-1.3.1/jasmine-html.js"></script>

    <script type="text/javascript" src="test.js"></script> // <3>

</head>
<body>

</body>
</html>
----
<1> Adding the Jasmine framework dependencies

<2> Adding ExtJS framework dependencies

<3> This is our skeleton ExtJS application that will setup "friendly" environment for components under the test. You can see content of `test.js` in the <<SKELETON_EXTJS_APP,following listing>>.

[[SKELETON_EXTJS_APP]]
.A ExtJS testing endpoint
[source,javascript]
----
Ext.Loader.setConfig({
    disableCaching: false,
    enabled: true,
    paths: {
        Test:   'test',       // <1>    
        SSC:    'app'          // <2>
        }
});

var application = null;

Ext.onReady(function() {
    application = Ext.create('Ext.app.Application', {   
        name: 'SSC',        // <3>
        requires: [
            'Test.spec.AllSpecs'        // <4>
        ],
        controllers: [
            'Donate'        // <5>
        ],
        launch: function() {
            Ext.create('Test.spec.AllSpecs');

            jasmine.getEnv().addReporter(new jasmine.TrivialReporter());        // <6>
            jasmine.getEnv().execute();
        }
    });
});
----
<1> Ext JS loader needs to know the location of the testing classes...

<2> ... and about location of production code.

<3> Create skeleton application in the namespace of the production code to provide the execution environment.

<4> The `AllSpec` class will be requesting loading of the rest of the specs. We will show code of `AllSpec` class in <<ALL_SPEC,next listing>>

<5> The skeleton application will test the controllers from the production application code

<6> This code initializes Jasmine environment and reporters.

[[ALL_SPEC]]
[source,javascript]
----
Ext.define('Test.spec.AllSpecs', {
    requires: [         // <1>
        'Test.spec.BasicAssumptions'
        /*, 'Test.spec.ModelAssumptions' */
    ]
});
----
<1> The `requires` property includes an array of Jasmine suites. All further tests will be added to this array. Ext JS framework will be responsible for loading and instantiation all test classes.

Here is how our typical test suite will be look like.

.A BasicAssumptions class
[source,javascript]
----
Ext.define('Test.spec.BasicAssumptions', {}, function() {   // <1>
    describe("Basic Assumptions: ", function() {            // <2>
        it("Ext namespace should be available loaded", function() {
            expect(Ext).toBeDefined();
        });
        it("SSC code should be loaded", function() {
            expect(SSC).toBeDefined();
        });
    });
});
----
<1> Wrap the Jasmine suite into an Ext JS class

<2> The rest of the code is very similar to the Jasmine code sample shown earlier in this chapter.


After setup the testing harness for SaveSickChild application we will suggest testing strategy for ExtJS applications. We will start with testing the models and controllers, after that we will test our views.

===== Testing The Models

_SaveSichChild.org_ home page displays information about the fund raising campaigns using a chart and a table views backed by collection of `Campaign` models. A `Campaign` model should have three properties: `title`, `description`, and `location`. The `title` property of the model should have a default value - `Default Campaign Title`. The `location` property of the model is required field.
In a spirit of TDD, let's write the <<CAMPMOD_SPEC,specification>> what will meet the requirements described above.

[[CAMPMOD_SPEC]]
.CampaignModelAssumptions specification
[source,javascript]
----
include::include/CampaignModelAssumptions.js[]
----
<1> By default, `Ext.data.Model` caches every model created by the application in a global in-memory array. We need to clean up the ExtJS model cache after each test run.

<2> Instantiate the `Campaign` model class to check that it exists.

<3> Next we need to check if model has all required properties. 

<4> The property `title` has a default value.

<5> Validation will fail on empty `location` property.

[source,javascript]
----
include::include/Campaign.js[]
----

* Test model / controller first.


* Test views
* Test whole application


==== Setting up the IDE for TDD

WARNING: Section under active development

In this section we will setup WebStorm to use the described above tools inside this IDE. We will show how to integrate Grunt tool with WebStrom to run grunt tasks from there. 

// TDB

===== Integrate the Grunt tool with WebStorm

Let's start with the Grunt setup. Currently, there is no native support of the Grunt tool in WebStorm IDE. But since Grunt can be launched from a command line, we can use a universal feature of the WebStorm IDE and configure it as an _External Tool_. Open WebStorm preferences and navigate to _External Tools_ section to get access to the external tools configuration as in <<FIG_SO_AND_SO>>.

.External Tools configuration window in WebStorm
image::fig_08_08.png[]

Click the `+` button to create new External Tool configuration.

.External Tool configuration
image::fig_08_09.png[]

1. You need to specify the full path to the application executable.

2. Some tools require to have the command line parameters. In this example, we explicitly specify the task runner configuration file (with the `--gruntifle` command line option) and thet task to be executed.

3. Also you need to specify the _Working Directory_ to run the Grunt tool. In our case, grunt configuration file is located in the root of our project. WebStorm allows to use macros to avoid hard-coded paths. Most likely, you don't want to setup external tools for each new project, just create a universal setup. In our example we use the `$ProjectFileDir$` macros will be resolved as current WebStorm project folder root.

4. WebStorm allows you to organize related tasks into logical groups.

5. You can configure how to access the external tool launcher.

When all of the above steps are complete you can find the launcher under _Tools_ menu as well under Main menu Editor menu, Project views and etc.  

.Grunt launcher available under _Tools/grunt_ menu
image::fig_08_11.png[]

Unit tests are really important as a mean to get a quick feedback from your code. You can work more efficient if you manage to minimize context switching during your coding flow. Also, you don't want to waste time digging through the menu items of your IDE, so assigning a keyboard shortcut for launching external tool is a good idea.

Let's assign a keyboard shortcut for our newly configured external tool launcher. Go to the _Keymap_ section in WebStorm Preferences. Use the filter to find our created launcher `jasmine: grunt test`. Specify either the Keyboard of the Mouse shortcut by double clicking on the appropriate list item.

.Setup keyboard shortcut for grunt launcher
image::fig_08_10.png[]

By pressing a combination of keys specified in the previous screen, you will be able to launch the grunt with Jasmine tests with one click of a button(s). WebStorm will redirect all the output from the grunt tool into its  Run window.

.Grunt output in WebStorm
image::fig_08_12.png[]

===== Setup WebStorm support for Jasmine library

//TBD

=== Summary

Testing is one of the most important processes of software development. Well organized testing helps keeping the code of an application in a good and working state. It's especially important in interpreted languages like JavaSctipt where there is no compiler to provide a helping hand to find lots of errors on very early stages. 

In this situation, static code analysis tools, like JSHint, could become very handy in helping with identifying typos and enforcing best practices accepted by the JavaScript community.

In enterprise projects developed with compiled languages people often debate if test-driven development is really beneficial. With JavaScript it's non-debatable unless you have unlimited time and budget and are ready to live with unmaintainable JavaScript. 

The enterprises that have adopted test-driven development (as well as behavior-driven development) can make the application development process more bulletproof by including test scripts in the continuous integration build process. 

Automating unit tests reduces the number of bugs and decreases the amount of time developers need to spend manually testing their code. If automatically launched test scripts (unit, integration, functional, and load testing) don't reveal any issues, you can rest assured that the latest code changes did not break the application logic, and that the application performs according to SLA. 

[bibliography]
- [[[flanagan]]] David Flanagan. 'Javascript. The Definitive Guide. 6th Edition'. O'Reilly. 2011.
- [[[fowler]]] Martin Fowler. 'Refactoring. Improving the Design of Existing Code' 2002 p.212